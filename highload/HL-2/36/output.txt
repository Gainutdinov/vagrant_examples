Задание:
Замечание: данное задание предполагает, что ранее были выполнены задания:
● HL 32. Prometheus: deploy
Замечание: в задании рассматривается мониторинг кластера Kubernetes с помощью внешнего Prometheus.
1. Установите Kubernetes версии 1.18.0 в конфигурации с тремя мастер-нодами.

```
https://dockerlabs.collabnix.com/kubernetes/beginners/Install-and-configure-a-multi-master-Kubernetes-cluster-with-kubeadm.html
```

2. Создайте ClusterRole для Prometheus:
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRole
metadata:
  name: prometheus-role
rules:
- apiGroups: [""]
  resources: ["pods", "endpoints", "services", "nodes", "nodes/proxy"]
  verbs: ["get", "list", "watch"]
- nonResourceURLs: ["/metrics"]
  verbs: ["get"]
3. Создайте ServiceAccount prometheus:
apiVersion: v1
kind: ServiceAccount
metadata:
  name: prometheus
  namespace: default
4. Создайте ClusterRoleBinding для привязки аккаунта к роли:
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRoleBinding
metadata:
  name: prometheus-binding
subjects:
- kind: ServiceAccount
  name: prometheus
  namespace: default
roleRef:
  kind: ClusterRole
  name: prometheus-role
  apiGroup: rbac.authorization.k8s.io

5. Получите token для ServiceAccount prometheus:
export TOKEN=$(kubectl get secrets -o
jsonpath="{.items[?(@.metadata.annotations['kubernetes\.io/service-account\.name']=='prometheus')].data.token}"|base64 --decode)
6. Убедитесь, что ServiceAccount prometheus имеет доступ к метрикам API-среверов:
curl -k https://<LOADBALANCER_IP>:6443/metrics --header "Authorization: Bearer $TOKEN" --insecure

```
root@ip-10-11-0-79:/home/ubuntu# curl -k https://54.189.198.148:6443/metrics --header "Authorization: Bearer $TOKEN" --insecure | head
  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current
                                 Dload  Upload   Total   Spent    Left  Speed
  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0# HELP aggregator_openapi_v2_regeneration_count [ALPHA] Counter of OpenAPI v2 spec regeneration count broken down by causing APIService name and reason.
# TYPE aggregator_openapi_v2_regeneration_count counter
aggregator_openapi_v2_regeneration_count{apiservice="*",reason="startup"} 0
aggregator_openapi_v2_regeneration_count{apiservice="k8s_internal_local_delegation_chain_0000000002",reason="update"} 0
# HELP aggregator_openapi_v2_regeneration_duration [ALPHA] Gauge of OpenAPI v2 spec regeneration duration in seconds.
# TYPE aggregator_openapi_v2_regeneration_duration gauge
aggregator_openapi_v2_regeneration_duration{reason="startup"} 0.806540134
aggregator_openapi_v2_regeneration_duration{reason="update"} 0.867507781
# HELP aggregator_unavailable_apiservice [ALPHA] Gauge of APIServices which are marked as unavailable broken down by APIService name.
# TYPE aggregator_unavailable_apiservice gauge
100 12288    0 12288    0     0   631k      0 --:--:-- --:--:-- --:--:--  631k
curl: (23) Failed writing body (0 != 4096)
root@ip-10-11-0-79:/home/ubuntu#

```

7. На ВМ c Prometheus создайте файл token и поместите в него полученный ранее токен.
8. Добавьте в файл docker-compose.yml монтирование созданного файла token в /etc/prometheus/token контейнера Prometheus.
9. Добавьте в scrape-configs (prometheus.yml) секцию мониторинга API-серверов кластера Kubernetes:
- job_name: 'kubernetes-apiservers'
  scheme: https
  tls_config:
    insecure_skip_verify: true
  bearer_token_file: /etc/prometheus/token
  kubernetes_sd_configs:
  - role: endpoints
    api_server: https://<LOADBALANCER_IP>:6443
    tls_config:
      insecure_skip_verify: true
    bearer_token_file: /etc/prometheus/token
  relabel_configs:
  - source_labels: [__meta_kubernetes_namespace, __meta_kubernetes_service_name, __meta_kubernetes_endpoint_port_name]
  action: keep
  regex: default;kubernetes;https
Рестартуйте стек Prometheus.
Используя WebUI Prometheus, убедитесь, что в Targets доступна информация об API-серверах кластера Kubernetes.

```
1.png
```

10. Добавьте в scrape-configs (prometheus.yml) секцию мониторинга нод кластера
Kubernetes:
- job_name: 'kubernetes-nodes'
  scheme: https
  tls_config:
    insecure_skip_verify: true
  bearer_token_file: /etc/prometheus/token
  kubernetes_sd_configs:
  - role: node
    api_server: https://<LOADBALANCER_IP>:6443
    tls_config:
      insecure_skip_verify: true
    bearer_token_file: /etc/prometheus/token
  relabel_configs:
  - action: labelmap
    regex: __meta_kubernetes_node_label_(.+)
  - target_label: __address__
    replacement: <LOADBALANCER_IP>:6443
  - source_labels: [__meta_kubernetes_node_name]
    regex: (.+)
    target_label: __metrics_path__
    replacement: /api/v1/nodes/${1}/proxy/metrics
Рестартуйте стек Prometheus.
Используя WebUI Prometheus, убедитесь, что в Targets доступна информация о нодах кластера Kubernetes.

```
2.png
```

11. Добавьте в scrape-configs (prometheus.yml) секцию мониторинга встроенного cAdvisor:
- job_name: 'kubernetes-cadvisor'
  scheme: https
  tls_config:
    insecure_skip_verify: true
  bearer_token_file: /etc/prometheus/token
  kubernetes_sd_configs:
  - role: node
    api_server: https://<LOADBALANCER_IP>:6443
    tls_config:
      insecure_skip_verify: true
    bearer_token_file: /etc/prometheus/token
  relabel_configs:
  - action: labelmap
    regex: __meta_kubernetes_node_label_(.+)
  - target_label: __address__
    replacement: <LOADBALANCER_IP>:6443
  - source_labels: [__meta_kubernetes_node_name]
    regex: (.+)
    target_label: __metrics_path__
    replacement: /api/v1/nodes/${1}/proxy/metrics/cadvisor
Рестартуйте стек Prometheus.
Используя WebUI Prometheus, убедитесь, что в Targets доступна информация метрик cAdvisor нод.

```
3.png
```

12. Выполните тестовый запрос параметра container_cpu_usage_seconds_total для определения текущей загрузки CPU контейнеров.

```
4.png
```

