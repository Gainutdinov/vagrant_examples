Задание:
Подготовка окружения
1. Создайте 3 виртуальных машины (ноды) u18-hadoop{1,2,3} следующей конфигурации:
○ Операционная система: Ubuntu 18.04
○ Количество ядер: 2 CPU
○ Оперативная память: 2 GB
○ Виртуальный диск: 20 ГБ
2. Обновите операционную систему на созданных нодах.
3. Добавьте записи для всех нодов в файл /etc/hosts на всех нодах кластера.
4. Установите рекомендуемую версию Java на нодах u18-hadoop{1,2,3}.
5. Установите сервисы ssh и pdsh. Они необходимы для удаленного управления сервисами Hadoop и улучшенного управления ssh.
Установка последней стабильной версии Hadoop
1. Скачайте последнюю стабильную версию Hadoop.
Подготовка к запуску кластера Hadoop
1. Распакуйте скачаную версию Hadoop и настройте очень важную переменную HADOOP_HOME.
2. Отредактируйте файл etc/hadoop/hadoop-env.sh, указав путь к расположению установленной версии Java в переменной окружения JAVA_HOME.
3. Проверьте, если скрипт Hadoop работает. Ны выходе Вы должны получить текст подсказки с параметрами запуска скрипта.
Запуск Hadoop в полном распределенном режиме
1. Создайте следующие файлы кофигурации:
○ файл core-site.xml, который должен указывать файловую систему по умолчанию, имя NameNode ВМ, а так же порт, который будут использовать DataNodes для отправки heartbeat
○ файл hdfs-site.xml, который должен указывать одну реплику блоков, на которые HDFS делит сохраняемые файлы
○ сделать YARN планировщиком заданий и основным рабочим фреймом для функционирования MapReduce, добавив конфигурацию в файл mapred-site.xml
○ добавить конфигурацию YARN в файл etc/hadoop/yarn-site.xml
○ сообщить мастер-ноде о всех существующих в кластере рабочих нодах путем перечисления их имен в файле etc/hadoop/workers
○ настроить параметры распредления памяти для YARN и MapReduce в файлах etc/hadoop/yarn-site.xml и etc/hadoop/mapred-site.xml
2. Создайте ssh доступ между u18-hadoop{1,2,3} без пароля. Для этого сгенерируйте локально новый ключ RSA, либо используйте готовый и скопируйте содержимое в файл ключей.
3. Скопируйте конфигурацию из папки etc/hadoop на все рабочие ноды.
4. Выполните запуск Hadoop:
○ выполните форматирование файловой системы HDFS с помощью команды hdfs и ее параметров выполнения.
○ запустите сервисы Hadoop при помощи скрипта start-all.sh.
Примечание: "маленький" слоник записывает логистику выполнения по умолчанию в директорию $HADOOP_HOME/logs, которая может быть изменена установкой переменной окружения $HADOOP_LOG_DIR. Еще
Примечание: иногда команда start-all.sh выдает ошибку. Полезные ссылки помогут.
○ попробуйте просмотреть веб интерфейс сервиса NameNode, по умолчанию он находится здесь: http://localhost:9870/
○ создайте директории /user и /user/<username> файловой системы HDFS, необходимые для выполнения работ MapReduce, используя команду hdfs и ее параметров выполнения.
○ скопируйте исходные файлы etc/hadoop/*.xml на HDFS в директорий input, предварительно создав его.
○ попробуйте выполнить файлы примеров share/hadoop/mapreduce/hadoop-mapreduce-examples-3.2.1.jar при помощи команды hadoop и ее параметров.
○ исследуйте файлы на выходе выполнения примеров, предварительно скопировав их на локальную систему при помощи команды hdfs.
○ по окончании исследований остановите сервисы Hadoop при помощи скрипта stop-all.sh.
