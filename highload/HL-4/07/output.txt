Задание:
1. Кто является первым обладателем права разработчика алгоритма MapReduce?

```
Авторами этой вычислительной модели считаются сотрудники Google Джеффри Дин (Jeffrey Dean) и Санджай Гемават (Sanjay Ghemawat), взявшие за основу две процедуры функционального программирования: map, применяющая нужную функцию к каждому элементу списка, и reduce, объединяющая результаты работы map [3]. В процессе вычисления множество входных пар ключ/значение преобразуется в множество выходных пар ключ/значение [4].
```

2. Сколько фаз включает в себя MapReduce и какие?

```
● Разбиение входных данных (Input Splits)
● Передача данных на предварительную оработку (Mapping)
● Перемешивание (Shuffling)
● Свёртка (Reduce)
```

3. С каким типом данных работает MapReduce?

```
Если обобщенно то ответ:
key-value pairs

Map принимает на вход список значений и некую функцию, которую затем применяет к каждому элементу списка и возвращает новый список;
Reduce (свёртка) – преобразует список к единственному атомарному значению при помощи заданной функции, которой на каждой итерации передаются новый элемент списка и промежуточный результат.
```

4. Почему нельзя сильно уменьшать Split-разбиения?

```
Однако также нежелательно иметь слишком маленькие split-разбиения. Когда разделения слишком малы, перегрузка управления split-разбиениями и созданием map-задач начинает доминировать в общем времени выполнения задания.
```

5. Насколько важны данные, полученные на этапе Map?

```
Это самый первый этап выполнения программы MapReduce. На этом этапе данные в каждом разбиении (split) передаются в функцию map для получения выходных значений.
```

6. Где находится Task Tracker?

```
On DataNodes
Multiple Task Trackers: действуют как slaves, каждый из которых выполняет свою работу.
```

7. Какие две функции необходимы при написании алгоритма выполнения любой задачи с использованием MapReduce? Приведите пример таких функций.

```
#map && reduce
void map(String name, String document):
// Входные данные:
// name – название документа
// document – содержимое документа
  for each word w in document:
    EmitIntermediate(w, "1");
// Функция, используемая рабочими нодами на Reduce-шаге
// для обработки пар ключ-значение, полученных на Map-шаге
void reduce(Iterator partialCounts):
    // Входные данные:
    //   partialCounts - список группированных промежуточных результатов. Количество записей в partialCounts и есть 
    //     требуемое значение
    int result = 0;
    for each v in partialCounts:
        result += parseInt(v);
    Emit(AsString(result));
```

